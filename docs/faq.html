
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>FAQ &#8212; Pricing Engine 2.2.0 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2.2.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  false,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Project History" href="history.html" />
    <link rel="prev" title="msecoreml package" href="build/apidoc/msecoreml/msecoreml.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="faq">
<span id="faq"></span><h1>FAQ<a class="headerlink" href="#faq" title="Permalink to this headline">¶</a></h1>
<div class="section" id="causal-inference">
<span id="causal-inference"></span><h2>Causal Inference<a class="headerlink" href="#causal-inference" title="Permalink to this headline">¶</a></h2>
<p><strong>Q: What is causal inference? How is this different than ML?</strong></p>
<p>Causal inference is about understand the true effect of a variable (or treatment), call it <span class="math">\(D\)</span>, on an outcome, call it <span class="math">\(Y\)</span>. How would <code class="docutils literal"><span class="pre">Y</span></code> change if we changed <code class="docutils literal"><span class="pre">D</span></code>? We want an unbiased estimate of <code class="docutils literal"><span class="pre">D</span></code>'s effect on <code class="docutils literal"><span class="pre">Y</span></code> including uncertainty measures of p-value or confidence intervals. This is what the statistical part of sciences (e.g. Econometrics and Biostats) often works towards. ML, on the other hand, is usually about coming up with a good predictor function of <code class="docutils literal"><span class="pre">Y</span></code> using many features <code class="docutils literal"><span class="pre">X</span></code> (that may include <code class="docutils literal"><span class="pre">D</span></code>). These are fundamentally different and therefore one should be careful when moving from one domain to the other or combining the two.
One important way that causal inference is the same is that there is no &quot;ground-truth&quot; that we can compare estimates against. For example, in ML it is common to iterate heavily on models and then to use a hold-out set of the data to prevent over-fitting. When looking for causal inference we can't do the same thing because we don't know what the right answer in the test set is. In causal inference therefore we are much more careful about how we do model iteration so as to prevent over-fitting. The general rule of thumb is that you should use the same data for selecting your model as you do to get estimates.</p>
<p><strong>Q: Why is causal inference so hard?</strong></p>
<p>When <code class="docutils literal"><span class="pre">D</span></code> is randomly assigned inference is straightforward and can be done using ordinary least squares (OLS) regression. When trying to draw conclusions from data where <code class="docutils literal"><span class="pre">D</span></code> wasn't randomly assigned this is more complicated. One has to control for factors that independently affects both <code class="docutils literal"><span class="pre">Y</span></code> and <code class="docutils literal"><span class="pre">D</span></code>. These are called confounders (call them <code class="docutils literal"><span class="pre">C</span></code>). Omitting these will cause our causal estimates to be wrong (&quot;omitted variable bias&quot;). Sometimes we know vaguely what <code class="docutils literal"><span class="pre">C</span></code> and if we have data on it we can try to control for it directly (what we will talk about here). If don't, then we have to look for slices of the data where there is &quot;exogenous variation&quot; so that looking at it in a particular way is like an experiment (instrumental variables, regression discontinuity).</p>
<p>When trying to directly control for confounder, we often aren't sure exactly what form it takes or how it interacts with other elements of the system. So we would like a flexible strategy for controlling for confounders. But OLS has bad statistical properties when there are lots of variables, this presents a tension. We deal with this using a method called DoubleML.</p>
<p><strong>Q: What is DoubleML?</strong></p>
<p>In DoubleML structure the overall causal inference question so as to split out the parts of causal inference that are pure prediction problems so that we can hand them over to ML. In our control-based approach this amounts to trying to estimate how the outcome is driven by confounders given a set of features, <code class="docutils literal"><span class="pre">f(X)</span></code>, and how <code class="docutils literal"><span class="pre">D</span></code> is driven by confounders, <code class="docutils literal"><span class="pre">g(X)</span></code>. We then remove the portions of <code class="docutils literal"><span class="pre">Y</span></code> and <code class="docutils literal"><span class="pre">D</span></code> that are driven by the confounders so that <code class="docutils literal"><span class="pre">Y_r=Y-f(X)</span></code> and <code class="docutils literal"><span class="pre">D_r=D-g(x)</span></code>, ie we are removing the &quot;predictable part&quot;. The remaining &quot;residuals&quot; now act like mini experiments and we can regress <code class="docutils literal"><span class="pre">Y_r</span></code> on <code class="docutils literal"><span class="pre">D_r</span></code> and OLS will give us the effect and statistical significance.</p>
<p><strong>Q: What can go in the predictor features set (<code class="docutils literal"><span class="pre">X</span></code>)?</strong></p>
<p>The only thing you shouldn't add to <code class="docutils literal"><span class="pre">X</span></code> is something that is caused by <code class="docutils literal"><span class="pre">D</span></code> and can effect <code class="docutils literal"><span class="pre">Y</span></code>. These are called &quot;bad controls&quot; and they will also bias our results for <code class="docutils literal"><span class="pre">D</span></code> (they capture part of the overall affect of <code class="docutils literal"><span class="pre">D</span></code> on <code class="docutils literal"><span class="pre">Y</span></code>). Often this is easily accommodated by using lagged values of controls so that <code class="docutils literal"><span class="pre">D</span></code> at a particular time couldn't cause <code class="docutils literal"><span class="pre">X</span></code> from earlier.</p>
<p><strong>Q: Why don't I just use a rich ML model to model <code class="docutils literal"><span class="pre">Y</span></code> as a function of <code class="docutils literal"><span class="pre">D</span></code> and <code class="docutils literal"><span class="pre">X</span></code>? If I use a linear model (e.g. Lasso) I can just get the coefficient, and in a non-linear model and can approximate the derivative of the prediction function with respect to the feature <code class="docutils literal"><span class="pre">D</span></code>.</strong></p>
<p>ML models broadly, as they usually optimize for out-of-sample fit, don’t provide treatment estimates that we think are “accurate” (“unbiased’), no matter if the effect is identified from a coefficient or by taking the partial-derivative of a complex prediction function. A simple example is that many models involve some sort of regularization/penalization so as not to overfit. Typically this means that coefficients on features are shrunk to zero (or set exactly to 0 if the features isn’t selected). This means that the coefficients will be wrong and it’s really hard to figure out how much they’re wrong! The take-away is that one doesn’t want to optimize on fit when trying to get good parameter estimates. That’s why in DoubleML&nbsp; the core treatments are separated from the control terms and only do ML fit-based penalization on the later.
ML models also don't provide p-values on coefficients. One can construct metrics that give a sense of coefficient stability (e.g. via bootstrapping), but that is inherently much different. A classic case is that features selected by a Lasso are not necessarily statistically significant in a (perfectly specific) linear regression. In DoubleML, that’s why we separate the prediction <code class="docutils literal"><span class="pre">f()</span></code> and <code class="docutils literal"><span class="pre">g()</span></code> from the effect estimation. Another way of seeing this is that related to the point above, if the estimates are biased and one doesn’t know by how much, one can’t really get p-values.</p>
<p>DoubleML also improves upon traditional controlling strategies by looking separately for how potential confounders could be driving sales and treatment variables (we residualize both). This gives us two chances of catching confounders and is superior when there are confounders that are highly related to treatment. The intuition is that omitted variable bias is proportional to the product of the omitted variable’s relation to treatment and sales and so therefore we want to be able to control for factors that are only moderately related to sales but strongly related to treatment and these are more likely to be missed if we just control for the relation to sales. An example of this type of situation would be if the end of the month strongly caused a retailer to cut their prices (e.g. trying to meet quotas) but also moderately affected consumer behavior (e.g. they have monthly budgets they are trying to stretch).</p>
</div>
<div class="section" id="model-building">
<span id="model-building"></span><h2>Model Building<a class="headerlink" href="#model-building" title="Permalink to this headline">¶</a></h2>
<p><strong>Q: General advice on building linear models</strong></p>
<p>Look at the PennState Stat501 - Regression Methods free online material. See for example:</p>
<ul class="simple">
<li><a class="reference external" href="https://onlinecourses.science.psu.edu/stat501/node/279">4.4 - Identifying Specific Problems Using Residual Plots</a> (Note: we already deal with non-constant error variance and we don't care as much about non-normal errors) and the multiple regressor version <a class="reference external" href="https://onlinecourses.science.psu.edu/stat501/node/317">7.4 - Assessing the Model Assumptions</a> (Note: we care most about the <strong>L</strong>inear and <strong>I</strong>ndependence assumptions)</li>
<li><a class="reference external" href="https://onlinecourses.science.psu.edu/stat501/node/343">11.7 - A Strategy for Dealing with Problematic Data Points</a> for how to deal with influential points: outliers (unusual y for an x) and high-leverage points (unusual x).</li>
<li><a class="reference external" href="https://onlinecourses.science.psu.edu/stat501/node/328">10.1 - What if the Regression Equation Contains &quot;Wrong&quot; Predictors?</a> What happens if you omit a necessary regressor? The coefficients on variables correlated with the omitted variable will be biased.</li>
<li><a class="reference external" href="https://onlinecourses.science.psu.edu/stat501/node/343">12 - Multicollinearity &amp; Other Regression Pitfalls</a> If your parameter changes a lot (even switch sign) when adding different controls, multicollinearity is the usual suspect. Basically, if your variables are positively correlated, they will compete for the same effect so the coefficients will be negatively correlated, which can lead to a wrong sign on one of the coefficients. We use a ridge in the last stage that helps correct the signs to some degree.</li>
</ul>
<p>Also, our linear model at the end is a Statsmodel linear model so have a look at their specific <a class="reference external" href="http://www.statsmodels.org/dev/stats.html#module-statsmodels.stats.stattools">diagnostics</a></p>
<p><strong>Q: Why is this coefficient different (e.g. wrong sign) than I expected?</strong></p>
<p>First off, if a coefficient is insignificant, then you should worry too much. An insignificant coefficient does not contradict either hypothesis that the true effect is positive or negative.</p>
<p>If a coefficient is significant and the &quot;wrong&quot; sign then several things could be going on. See the above links for more diagnosis.</p>
</div>
<div class="section" id="package-usage">
<span id="package-usage"></span><h2>Package usage<a class="headerlink" href="#package-usage" title="Permalink to this headline">¶</a></h2>
<p><strong>Q: What parts use randomization?</strong></p>
<p>The main source of randomness is the shuffling used in the data-splitting for separately fitting the baseline models. You can eliminate the randomness by providing your own splitter to <a class="reference external" href="build/apidoc/pricingengine\pricingengine.estimation.html#pricingengine.estimation.dynamic_dml.DynamicDML">DynamicDML</a>. See <code class="docutils literal"><span class="pre">msecore.randomex.set_random_seeds()</span></code> to set a random seed. Some of the models use cross validation, but none currently randomize; <code class="docutils literal"><span class="pre">RidgeCV</span></code> uses the non-random leave-one-out method and <code class="docutils literal"><span class="pre">LassoCV</span></code> uses a non-random K-fold split. The models that explicitly randomize (<code class="docutils literal"><span class="pre">RandomForest</span></code> and <code class="docutils literal"><span class="pre">BoostedTrees</span></code>) accept a <code class="docutils literal"><span class="pre">random_state</span></code> argument. The current base optimizations (<code class="docutils literal"><span class="pre">sklearn</span></code>, <code class="docutils literal"><span class="pre">statsmodels</span></code>) do not appear to use randomization in their solvings.</p>
<p><strong>Q: How can I use the package in AzureML Studio/Workbench?</strong></p>
<p>Azure ML Studio uses Python 2.7 which is incompatible with our package.</p>
<p>Azure ML Workbench, however, works fine as it uses Python 3.5. The only package you will likely need to install in addition to the base environment is <code class="docutils literal"><span class="pre">statsmodels==0.8.0</span></code>.</p>
</div>
<div class="section" id="internal-operation">
<span id="internal-operation"></span><h2>Internal Operation<a class="headerlink" href="#internal-operation" title="Permalink to this headline">¶</a></h2>
<p><strong>Q: What scaling or normalization is used in estimation.</strong></p>
<p>Normalization happens in two places. First, at both the baseline and causal stage, <code class="docutils literal"><span class="pre">VarBuilder</span></code>s take their core variable and normalize them to have mean=0 and var=1 (if they are interacted with other variables those are brought without modification). Second, at the causal-stage if a core-variable is marked as &quot;unpenalized&quot; then it is scaled so that it is not significantly affected by penalization. Low-level models will see normalized features and therefore their &quot;raw&quot; coefficients/standard errors are transformed by <code class="docutils literal"><span class="pre">DynamicDML</span></code> for use by the user.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Pricing Engine</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="classes.html">Class Hierarchy</a></li>
<li class="toctree-l1"><a class="reference internal" href="build/apidoc/pricingengine/pricingengine.html">pricingengine package</a></li>
<li class="toctree-l1"><a class="reference internal" href="build/apidoc/msecore/msecore.html">msecore package</a></li>
<li class="toctree-l1"><a class="reference internal" href="build/apidoc/msecoreml/msecoreml.html">msecoreml package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">FAQ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#causal-inference">Causal Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-building">Model Building</a></li>
<li class="toctree-l2"><a class="reference internal" href="#package-usage">Package usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#internal-operation">Internal Operation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="history.html">Project History</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="build/apidoc/msecoreml/msecoreml.html" title="previous chapter">msecoreml package</a></li>
      <li>Next: <a href="history.html" title="next chapter">Project History</a></li>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Matt Goldman, Brian Quistorff.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
    </div>

    

    
  </body>
</html>